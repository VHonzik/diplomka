\chapter{Background}
\label{chap:bg}
\section{Related work}

\citet{ha2012combining} talk about an `information gaps' caused by existence of a non-dialogue communication stream. They concluded that the posture of user, an example of implicit information from the non-dialogue streams, is a significant attribute in modeling of dialog acts. Their goal is to overcome this `information gaps' through machine learning techniques. A shared view of the virtual world in this thesis is also a form of non-dialogue stream, with which must the navigation system work. I also try to apply machine learning to help with language generation.

\citet{viethen2011generating} compare traditional algorithmic approaches with alignment approaches based on psycho-linguistic models for the REG. They use large data-set (16,358 referring expressions) of direction giving task on a shared 2D visual scene introduced by \citet{louwerse2007multimodal}. They use three feature sets: traditional REG, alignment and independent (general information about the scene) to build decision tree models (concretely C4.5) combining these feature sets. The alignment based models outperform the traditional REG ones and the best model combines all feature sets to achieve accuracy 58.8\% and DICE score 0.81. Not using traditional algorithmic REG features did not result in a significant decrease of accuracy, suggesting that the visual context doesn't play such an important role as it was believed in the REG research so far.  \citet{viethen2011impact} verified this surprising conclusion by varying the visual context. They argue that the relative simplicity of visual scenes used in contemporary research might be the cause of insignificance of the visual context. I would argue that 3D  virtual world explored in this thesis is more complex then theirs and therefore this paper can provide some insight into these questions.  

\citet{stoia2006sentence} were interested in timing of the first reference to the target in 3D virtual world. They predicted whether direction giver refers to the target or delay the reference based on the spatial data. Their attributes were angle and distance to the target, number of visible distractors (either same category as target or all of them) and whether the target is visible. The most important feature in decision tree model was number of visible distractors followed by angle and distance. They achieved 86\% accuracy, compared 70\% baseline. The baseline was to refer when the target is visible and to delay the reference when the target isn't visible. Part of the machine learning attempts of this thesis is to replicate first reference timing of \citet{stoia2006sentence} on GIVE dataset.

\citet{stoia2006noun} developed decision trees to generate a noun phrase, specified by three slots: determiner/quantifier, pre-modifier/post-modifier and head noun. They used a data-set from 3D virtual world navigation task similar to GIVE dataset. Four categories of features were used: dialog history, spatial and visual features, relation to other objects in the world and object category. The decision trees revealed significant dependencies between the slots and importance of the spatial features. Interestingly, they used three types of system's evaluation. The exact match evaluation produced 31.2\% accuracy compared to 20\% most-frequent baseline. Comparison with hand-crafted Centering algorithm \citep{kibble2000integrated} ended with similar accuracy, favoring the machine-learning approach for requiring less structural analysis of the input text. Lastly, when human judged the system output, it was at least equal or preferred to original spontaneous language in 62.6\% (inter-annotator reliability $\kappa = 0.51$).

\citet{gallo2008production} showed that the Fruit Carts corpus can be used in NLG by case study on message complexity and structural realizations. A logistic regression confirmed that the complexity of verb arguments affects production choice between mono-clausal or bi-clausal structure. In more general terms, the complexity of the virtual environment affects how people speak on all linguistic levels. Referring expression generation should take that into consideration.

\citet{clark2004speaking} were examining speakers' monitoring of addressees in a Lego-building experiment. One participant - director - knew 10 Lego models and how to build them. The director was verbally instructing second participant - builder - to build these models. In one group the director could see the builders workspace, in second group he could not and in a third the instructions were audio-taped and simply passed onto the builder. Builders communicated with the directors on the workspace through head gestures and manipulating blocks (placing, exhibiting or poising and so on). When the workspace was blocked of, the task took much longer. In the audio-taped group the builders made many more errors. Directors often altered their utterances midcourse based on builders actions.