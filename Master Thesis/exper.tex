\chapter{Experiment on RE}
Trough out this thesis, I was interested in a strategy of referencing, where the first reference does not always uniquely identifies the target object. Instead, the strategy relied on a feedback and additional references, which together with the first reference formed a chain of references. I wondered, what is the effect of this splitting of the information across more references. After not being able to model this behaviour through methods of machine learning, I decided to look at that strategy under more controlled conditions of an experiment.

In the first section, I'll present my hypothesis concerning the strategy of splitting references. The second section will describe the experimental set-up. In the last section, I'll summarize the results of the experiment.

\section{Hypothesis}
To evaluate strategy of splitting references, I compared two NLG systems, which I have built to resemble behaviour observed in the S-GIVE dataset. The two systems are identical, except for a difference in REG strategy for the target button. One would represent the strategy of splitting references, while the other one would represent more standard approach of referencing. They will be thoroughly described in Section \ref{sec:exper-setup}.

I've formulated my hypothesis as a pair of null and alternative hypotheses:

\begin{nullhypo}
Distributing information to uniquely identify the referent across multiple referring expressions separated by non-negligible time intervals does not have an impact on the task proficiency.
\end{nullhypo}

\begin{alterhypo}
Distributing information to uniquely identify the referent across multiple referring expressions separated by non-negligible time intervals has an impact on the task proficiency.
\end{alterhypo}

Measuring task proficiency can be done in several ways. In previous chapters, I've often employed duration of the experiment. However, for this experiment I've chosen more specific measure, in order to diminish effects of other factors. Measuring time from the point of uttering the first reference up to the pressing of the targeted button not only diminishes effects of other variables in the navigation process, but can also be interpreted as a measure how well were the references understood by IF.

\section{Experimental set-up}
\label{sec:exper-setup}
I've tested my hypothesis through a human subjects evaluation. Each subject did 5 virtual worlds from GIVE scenario. One of the worlds was a short tutorial world. This tutorial world was excluded from the analysis and served the purpose of diminishing the effect of learning. After the tutorial world, the subjects did 4 evaluation worlds in a random order. The two tested NLG systems were assigned to each world semi-randomly to ensure both of the systems appeared twice. Please note, that the tutorial world was created in such way that the two tested NLG systems behaved the same way and therefore none of the systems had an advantage in number of trials. I used text instruction presented on the screen as in the GIVE Challenge instalments. Using some sort of speech synthesis or even recorded instructions was beyond the scope of this experiment.

The worlds were similar to the GIVE challenge worlds. Maps generated by GIVE map-viewer for all of the 4 evaluation worlds can be found in Figures \ref{fig:exper-world1}, \ref{fig:exper-world2}, \ref{fig:exper-world3} and \ref{fig:exper-world4}. I did not include any alarm tiles or alarm-causing buttons in the worlds, to avoid situation where IF would loose. I also avoided complex arrays of buttons, which were present in some of the S-GIVE worlds.

\begin{figure}[!htbp]
  \centering
	\includegraphics[width=0.7\textwidth]{Images/experiment-world-2}
	\caption{Map of the evaluation world 1.}
	\label{fig:exper-world1}
\end{figure}

\begin{figure}[!htbp]
  \centering
	\includegraphics[width=0.7\textwidth]{Images/experiment-world-3}
	\caption{Map of the evaluation world 2.}
	\label{fig:exper-world2}
\end{figure}

\begin{figure}[!htbp]
  \centering
	\includegraphics[width=0.7\textwidth]{Images/experiment-world-4}
	\caption{Map of the evaluation world 3.}
	\label{fig:exper-world3}
\end{figure}

\begin{figure}[!htbp]
  \centering
	\includegraphics[width=0.7\textwidth]{Images/experiment-world-5}
	\caption{Map of the evaluation world 4.}
	\label{fig:exper-world4}
\end{figure}

I have called the two NLG systems Alpha and Beta. Since they are almost identical except for a REG strategy for the buttons, I will describe the Alpha system and simply point out the differences between it and Beta system at the end. As was previously mentioned in Chapter \ref{chap:ml}, the NLG systems are inspired by the analysis of S-GIVE dataset. Even though S-GIVE dataset is spoken word, I managed to transform some ideas from the spoken data to the written instructions.

Because the final systems are not subjects of this thesis, but merely a device to examine a NLP phenomenon, I will stick to high-level descriptions of the ideas behind them and avoid exhaustive software engineering description, such as class diagrams and similar devices.

First thing I would like to address is the timing. In spoken S-GIVE scenario the IG knows when the IF heard the RE. That's is however unknown for written instructions. I solved this problem by estimating the timing with an average reading speed of 150 words per minute. This can negatively affect the task proficiency because of the learning, but is not easily solved in the framework I was using.

For the direction giving, Alpha system uses 4 directions. The were heavily used in S-GIVE dataset even though sometimes enhanced by adjectives. The directions are simple: in front of the IF, left, right and behind the IF; all from the IF point of view. In conjunction with RE which use relations between world's entities, these 4 directions are sufficient to describe the path for IF. Suppose we consider $0^{\circ}$ a direction the IF is facing, then I've chosen the limits for the 4 directions as follows: in front $\langle-35^{\circ},35^{\circ}\rangle$, right $(35^{\circ},145^{\circ})$, behind $\langle145^{\circ},-145^{\circ}\rangle$ and left $(-145^{\circ},-35^{\circ})$. The system uses them as in the following example: ``Press the green button on your left.''

Before focusing on RE to the target button, I will report on how I implemented navigating through the rooms. In a relatively simple scenarios with rooms and mainly straight corridors, the system can simply create a RE for the door leading to the next planned room, once the IF entered a new room. Adding verbs of movement such as ``go'' to this RE is a simple, yet in the S-GIVE dataset common method for navigating in GIVE scenario. Example of such sentence is: ``Go through the door in front of you.'' The only complication is that with only 4 directions, other doors can be present in the same direction as the target door. I've solved this by another RE, identifying the target door using its relative position in the group of distracting doors: ``The door closest to you.'' Whenever this specification is needed, I've also added positive feedback when the IF is heading towards the correct doors and negative feedback if he/she enters a wrong room. I have also enhanced this subsystem by two additional improvements commonly seen in S-GIVE dataset.

First, when IF is only passing through the room on his way to a next one, I modified the language realization to take advantage of that fact. The system will produce expressions such as: ``Make a left.'' or ``Keep going straight.'' This adds variability to the NLG system and makes it more human-like.

Second, I exploited the room memory, first presented in Section \ref{sec:room-memory-ml}. When IF is immediately returning to the room he/she was just in and the time elapsed since he/she was there is not large (less than 20 seconds), the system will produce an expression such as: ``Go back to the room you were just in.'' This addition not only increase human-likeness, but I would argue also has an impact on the task efficiency, since it avoids the need a lot of problems in standard method described before.

The most complicated task are REs to a target button. This is where the systems Alpha and Beta differ. Once IF enters the room where a button needs to be pressed, the systems decide whether a reference containing the color of the button and the direction to the button will uniquely identifies the target button. That is, whether there are distracting buttons of the same color in the same direction. If there are none, both systems simply generate a RE like this one: ``Press the green button behind you.'' However, if this (first) RE would not uniquely identify the button, additional information must be provided. The additional information picks out the target button from the group of distractors. That is done either through a landmark, which I have placed in worlds so it is possible in most cases or it is done in a similar way the door specifying RE were created. Both systems are flexible enough to be able to provide unique identification to a great number of cases.

The system Beta will present that additional information as part of the first RE. System Alpha, on the other hand, separates this additional information to a new RE, which is not presented immediately. The system wait until the target button is visible and only then presents the second RE. Since the first RE contains direction, it is presumed the IF will eventually turns toward the target button.

In cases where additional information is needed, both systems provide positive feedback when IF is close and looking at the target button, measured by multiplying the distance between the IF and target button and the angle between them. Once a button was pressed, either positive or negative feedback is generated, depending whether IF pressed the correct button.

That concludes the high-level overview of the Alpha and Beta systems.

\section{Results}