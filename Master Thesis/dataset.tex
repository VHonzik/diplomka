\chapter{The S-GIVE Dataset}
After GIVE 2.5 instalment presented in Chapter \ref{chap:give-challenge}, Prof. Kristina Striegnitz, Ph.D., one of the organizers of the GIVE Challenge, became interested in spoken communication and therefore decided to collect a new dataset, called the S-GIVE Dataset. This chapter serves as an introduction and analysis of this dataset.

As a side note, \citet{striegnitz2012referring} report on a smaller German dataset, which is similar to the one I will be talking about. 

In the first section, I will introduce the dataset and provide technical details of how it was created. Section \ref{sec:world-demo-factors}, will, after the fashion of the GIVE Challenge look at how world and demographic factors influenced the task performance. The next section analyses REs in the dataset. The last section explores the phenomenon of chains of references.

\section{General overview}
\label{sec:general-overview}
The S-GIVE dataset is different from previous GIVE Challenge experiments because the IG's instructions were of a spoken form. That changes many aspects of the discourse. For one thing, the IG knows when the IF received his instruction, which is not true for the written instructions. That promotes faster feedback and allows interrupting during an instruction. However, in some cases, the spoken word tends to be less formal and grammatically correct. Moreover, interjections are very common, as are incomplete sentences. That makes the S-GIVE dataset complicated yet interesting to explore.

The data-collection started in July and finished in November of 2012. Through that period 21 interactions between two human subjects were recorded. Originally, 22 pairs participated, but one of the pair failed to finish the tasks and is excluded from the dataset. The subjects were asked to bring someone they know and they were financially compensated for the effort. 

The set-up for the experiment is shown in Figure \ref{fig:give-experiment-setup}. One human subject was an instruction giver (IG). He/she is on the right in Figure \ref{fig:give-experiment-setup}. His/her role was essentially the role of the NLG system in the GIVE Challenge. He/she was able to see a map of the world, which was updated in real-time and he/she got information about all necessary steps to finish the task. In addition, he/she was able to see the other person's client screen. He/she communicated with the other person through a microphone and his/her goal was to navigate the other person through the world and make him/her finish the treasure-hunt.

\begin{figure}[!htbp]
  \centering
	\includegraphics[width=0.7\textwidth]{Images/experiment-set-up}
	\caption{Experiment set-up of data collection}
	\label{fig:give-experiment-setup}
\end{figure}

The other person was an instruction follower (IF). He/she is on the left in Figure \ref{fig:give-experiment-setup}. He/she interacted with the client and moved the avatar around the world and was able to press buttons. The IF listened to the IG's instructions through a headset.

Each pair did one short tutorial world. After that they switched the roles of instruction giver and instruction follower. Following the tutorial was one ``normal'' world randomly chosen from two variants, marked world 1 and world 3 in the dataset. Maps of the worlds 1 and 3 are in Figures \ref{fig:dataset-world1} and \ref{fig:dataset-world3} respectively. Finally they did a difficult version of the other variant (if they started with world 1 the difficult version was for world 3 and vice versa). The difficult versions are marked 1-d and 3-d in the dataset. A difficult version of the world had an increased number of distracting buttons and landmarks compared to the ``normal'' version, as can be seen in the map of world 1-d in figure \ref{fig:dataset-world1d}. If not present in the report or not stated otherwise, the short tutorial worlds are normally excluded from the analysis.

\begin{figure}[!htbp]
  \centering
	\includegraphics[width=0.7\textwidth]{Images/dataset-world1}
	\caption{Map of the world 1 - normal version.}
	\label{fig:dataset-world1}
\end{figure}

\begin{figure}[!htbp]
  \centering
	\includegraphics[width=0.7\textwidth]{Images/dataset-world3}
	\caption{Map of the world 3 - normal version.}
	\label{fig:dataset-world3}
\end{figure}

\begin{figure}[!htbp]
  \centering
	\includegraphics[width=0.7\textwidth]{Images/dataset-world1d}
	\caption{Map of the world 1 - difficult version.}
	\label{fig:dataset-world1d}
\end{figure}

Similarly to the GIVE Challenge, after all 3 rounds subjects were asked to fill in a questionnaire. Its purpose was to get demographic and other relevant information on subjects. The questionnaire can be divided into three parts. The first part was only filled out by the IF and rated the IG and his instruction giving on a scale from 1 to 7. The complete list of the first part questions follows: 

\begin{enumerate}
\item
Overall, my partner gave me good instructions.
\item
Interacting with my partner wasn't annoying at all.
\item
My partner's instructions were clearly worded.
\item
When I had problems with the instructions, we solved them quickly.
\item
I enjoyed solving the task.
\item
I felt I could trust my partner's instructions.
\item
I really wanted to find that trophy.
\item
My partner immediately offered help when I was in trouble.
\item
I would recommend this experiment to a friend.
\item
My partner's instructions were not repetitive.
\end{enumerate}


The second part was filled by both the IF and the IG and was concerned with their navigation skills. To measure the ability to navigate in the world the Santa Barbara Sense of Direction (SBSOD) scores were used \citep{hegarty2002development}. Again the questions were on a scale from 1 to 7. Note that some of the question in the following list are of positive nature (higher rating equals better navigation skill) while other are of negative nature, therefore these scores had to be normalized.

\begin{enumerate}
\item
I am very good at giving directions.
\item
I have a poor memory for where I left things.
\item
I am very good at judging distances.
\item
My "sense of direction" is very good.
I tend to think of my environment in terms of cardinal directions (N, S, E, W).
\item
I very easily get lost in a new city.
\item
I enjoy reading maps.
\item
I have trouble understanding directions.
\item
I am very good at reading maps.
\item
I don't remember routes very well while riding as a passenger in a car.
\item
I don't enjoy giving directions.
\item
It's not important to me to know where I am.
\item
I usually let someone else do the navigational planning for long trips.
\item
I can usually remember a new route after I have travelled it only once.
\item
I don't have a very good "mental map" of my environment.
\end{enumerate}


Finally, the last part of the questionnaire was of a demographic character. We can see questions about age, gender, language and computer expertise, 3D games experience and knowledge of the partner in following list.

\begin{enumerate}
\item
What is your age?
\item
Are you male of female?
\item
What is your profession / major / favorite subject in school?
\item
How would you rate your computer expertise?
\item
How familiar are you with 3D computer games?
\item
How many hours per week to you play 3D computer games?
\item
Was there a time in your life when you played more 3D computer games? If so, how many hours did you play then?
\item
What languages do you speak? Please indicate how well you speak each on a scale from 1-5, where 5 is your native language.
\item
Did you already know the second participant?
\item
How well do you know the second participant?
\item
Have you worked collaboratively with the second participant before? (For example, when doing homework or preparing a class presentation?)
\item
Have you played 3D computer games with the second participant before?
\end{enumerate}

Many of these questions are explored in the next section as  potential factors influencing the task performance. 

As was mentioned in Chapter \ref{chap:give-challenge}, the entire session is logged to a database. The player's position, orientation and all visible objects are logged at a fixed rate. Moreover, other information such as buttons presses or the end of the session are also stored in the logs. Because the worlds are static, distances and angles between the IF and other game objects are easily computed from these logs.

Apart from the logs, there are of course sound files of the IG giving directions. These were transcribed and together with some information from the logs transformed into ELAN files. ELAN is an annotation software \citep{sloetjes2008annotation}. I will use the term \textit{automatic annotations} for the ELAN files created from the logs and transcribed audio (however note that transcribing audio was done manually). 

Building on top of these automatic annotations are manual annotations. They are primarily concerned with referring expressions and also stored in ELAN format. Most referring expressions in GIVE aim to locate a button, which needs to be pressed. I will call the button, which is a goal of a referring expression, the target button. Which button is the target button of a reference is one of the layers in the manual annotations. Another layer of the annotations is some basic categorization of the references, whether it is a reference to a single button, to a group of button, to a landmark and so on. The third layer looks deeper into the contents of the reference. It notes whether the reference contains for example the color of a button, whether distractors or landmarks are part of the reference or whether the reference explicitly points out that the button was already pressed before.

The previously mentioned logs, automatic annotations and manual annotations together form the dataset this chapter is dealing with.

An example of an interaction between an IF and an IG is in the following text. Spatial information is transcribed in parentheses for the sake of clearness.

\begin{verse}
(IF enters a room)\\
IG: Go towards the red buttons.\\
(IF turns right and start walking, but he turns too much)\\
IG: No the ones next to the lamp...\\
(IF corrects his direction)\\
IG: Yeah that lamp. On the right.\\
(IF is facing three buttons.)\\
IG: Press the button on the wall you are looking at, that's far from the lamp and on the left. \\
(IF goes towards the correct button and stops close to him)\\
IG: Press it.\\
\end{verse}

Next section, looks at how world selection and demographic factors affected the task performance.

\section{World and Demographic factors}
\label{sec:world-demo-factors}
As was noted repeatedly in Chapter \ref{chap:give-challenge}, the world had significant influence on the task success rate in GIVE Challenge. However in the GIVE Challenge the worlds were designed to be of a different difficulty, whereas in the S-GIVE dataset they were designed to be similar in terms of the difficulty to minimize effects outside of the navigation strategy. In addition, all the sessions were successful except for one which was discarded. The question about the influence of the worlds must be reformulated, since the task success rate no longer makes sense. Instead, I will measure task performance by time required to finish the task (duration) and also use other performance measure when appropriate.

Despite the design choices, I found that the normal worlds 1 and 3, had a different mean duration (p-value $0.0473$ for unpaired two-sample t-test). There are multiple explanation for this difference. The relatively small number of subjects is certainly one of them. We can also notice in Figure \ref{fig:dataset-world3} slightly complicated system of hallways in the center of world-3. But this discovery does not have a major influence on my work. Moreover, the difficult worlds did not have significant difference between their mean duration (p-value $0.6195$ for unpaired two-sample t-test).

Another thing I was interested in was the influence of the gaming experience of both participants on certain performance measures, namely on the duration, on the average speed of IF movement and the time the IF spent moving. The average speed of the IF is simply a total distance the avatar controller by IF travelled in a session divided by the duration. The time the IF spent moving aggregates the time where avatar wasn't either motionless or wasn't only rotating in place. 

I found correlations between gaming experience and these variables. Table \ref{tab:demfactors-gaming} shows the correlation matrix between gaming experience and performance measure.  Not surprisingly, these correlation are especially high for the IF, since he/she is the one who is actually playing the world, but the IG gaming experience seems to have some effect as well. The past gaming experience (questions 7 in third part of the questionnaire) is more important than contemporary playing (question 6 in the third part of the questionnaire). Most prominent are the familiarity of IF with 3D games (question 5),  the IF hours per week spent playing games at the past peak gaming period (question 7), the same variable for IG and hours spent gaming per week for IF at present (question 6). For the difficult worlds some correlations change slightly. IF's gaming at past peak period has much weaker correlation with duration here. In general, individuals who are familiar with games (gamers) take less time to finish the world, they spent more time moving and they have higher speed.

VERIFY CORRELATIONS

\begin{table}[!htbp]
 \centering
\begin{tabular}{llccc}
\toprule
World & Question  & Duration & Speed & Time moving  \\
\midrule
Normal 	& IF hours/week peak gaming (7) 	& -0.411 &	0.486 &	0.428\\
 		& IF hours/week now 	(6)			& -0.366	 & 	0.338 &	0.255\\
 		& IF familiarity 3D games (5)	& -0.590	 &	0.720 &	0.664\\
 		& IG hours/week peak gaming (7) 	& -0.359 &	0.450 &	0.435\\
 		& IG hours/week now 	(6)			& 0.079	 &	0.155 &	0.180\\
 		& IG familiarity 3D games (5)	& -0.230 &	0.221 &	0.224\\
\midrule
Difficult& IF hours/week peak gaming (7) & 0.111 &	0.199 &	0.135\\
 		& IF hours/week now (6)			& -0.388 &	0.312 &	0.233\\
 		& IF familiarity 3D games (5)	& -0.478 &	0.569 &	0.520\\
 		& IG hours/week peak gaming (7) 	& -0.287 &	0.715 &	0.715\\
 		& IG hours/week now (6)			& 0.149 &	0.348 &	0.420\\
 		& IG familiarity 3D games (5)	& 0.009 &	0.403 &	0.473\\
\bottomrule
\end{tabular}
\caption{Correlation matrix of gaming experiences and performance measures}
\label{tab:demfactors-gaming}
\end{table}

I also looked at the influence of SBSOD scores (second part of the questionnaire) on the task proficiency. A correlation matrix revealed weak or almost no correlation between SBSOD scores and the time needed to complete the world, as can be seen in Table \ref{tab:demfactors-sbsod}. In the difficult worlds, however, the correlation became slightly stronger.

\begin{table}[!htbp]
 \centering
\begin{tabular}{llc}
\toprule
 World & Role   & Duration \\
\midrule
Normal & IF &	-0.085\\
 & IG &	-0.082\\
\midrule
Difficult & IF & 0.162\\
 & IG &	-0.210\\
\bottomrule
\end{tabular}
\caption{Correlation between SBSOD scores and duration}
\label{tab:demfactors-sbsod}
\end{table}

NOTE ADD T-TEST

The data suggest that there is positive correlation between male gender and task proficiency measured as duration. Table \ref{tab:demfactors-gender} shows these correlations. The effect of male IG diminishes in the difficult worlds but the effect of IF is even stronger in the difficult worlds. However there are several facts to take in consideration here. First of all, we don't have enough data to have a statistically significant conclusion. This correlation might have also been caused by having more male gamers than female gamers. In fact, Table \ref{tab:demfactors-gender-fam} suggest so. Lastly, there has been research about influence of gender on spatial cognition and mental rotation; an example of more recent one is \citep{geary2000sex}. They conclude that males are more proficient in tasks requiring mental rotation. Since the IGs have to do mental rotation while giving direction in GIVE scenario, this might be a source of the correlation. Another paper worth considering on this topic is \citep{moffat1998navigation}, which found a gender difference in time required to finish a virtual maze.

\begin{table}[!htbp]
 \centering
\begin{tabular}{llc}
\toprule
 World & Role   & Duration \\
\midrule
Normal & IF &	-0.234\\
 & IG &	-0.277\\
\midrule
Difficult & IF & -0.349\\
 & IG &	-0.106\\
\bottomrule
\end{tabular}
\caption{Correlation between male gender and duration}
\label{tab:demfactors-gender}
\end{table}

\begin{table}[!htbp]
 \centering
\begin{tabular}{lc}
\toprule
Role    & Familiarity with 3D games \\
\midrule
 IF &	 0.341\\
 IG &	0.661\\
\bottomrule
\end{tabular}
\caption{Correlation between male gender and familiarity with 3D games}
\label{tab:demfactors-gender-fam}
\end{table}

Table \ref{tab:demfactors-age} shows correlation matrix for age. The age of the IF has a positive correlation with task proficiency measured in duration, and in difficult worlds this correlation is one of the strongest ones. Older IF are also moving less and are generally slower. For IG the correlations have the same direction, however they are much weaker.

\begin{table}[!htbp]
 \centering
\begin{tabular}{llccc}
\toprule
World & Role  & Duration & Speed & Time moving  \\
\midrule
Normal 	& IF & 0.175 & -0.467 & -0.448\\
 		& IG & 0.275 & -0.098 & -0.125\\
\midrule
Difficult& IF & 0.614 &	-0.275 &-0.196\\
 		& IG  & 0.016 &	-0.217 &-0.232\\
\bottomrule
\end{tabular}
\caption{Correlation matrix of age and performance measures}
\label{tab:demfactors-age}
\end{table}

ADD CORRELATIONS OF AGE WITH GAMING EXPERIENCE

Lastly I was interested how familiarity of participants with each other (questions 9-12 in the third part) influenced the task performance. Table \ref{tab:demfactors-famother} shows, that knowing the partner had a positive impact on task efficiency. The most correlated question was question 10: how well they know each other.

\begin{table}[!htbp]
 \centering
\begin{tabular}{llc}
\toprule
World & Question  & Duration \\
\midrule
Normal 	& IF Co-players in past (12) 	& -0.038\\
 		& IF Collaborative work 	(11)		& 0.109	 \\
 		& IF how well know each other (10)		& 0.529\\
 		& IF know each other (9)			& 0.164	\\
 		& IG Co-players in past (12) 	& -0.124\\
 		& IG Collaborative work 	(11)		& 0.189	 \\
 		& IG how well know each other (10)		& 0.420\\
 		& IG know each other (9)			& 0.177	\\
\midrule
Difficult& IF Co-players in past (12) 	& -0.078\\
 		& IF Collaborative work 	(11)		& 0.170	 \\
  		& IF how well know each other (10)		& 0.437\\
 		& IF know each other (9)			& 0.247	\\
 		& IG Co-players in past (12) 	& 0.291\\
 		& IG Collaborative work 	(11)		& 0.245	 \\
 		& IG how well know each other (10)		& 0.361\\
 		& IG know each other (9)			& 0.189	\\
\bottomrule
\end{tabular}
\caption{Correlation between participants familiarity and duration}
\label{tab:demfactors-famother}
\end{table}

Exploring interesting correlations, I will now focus on RE.

\section{Referring expressions}
Because REs are the main focus of my research, this section serves as a brief introductory analysis of REs in the S-GIVE dataset.

Overall, 793 REs were annotated in the manual annotations. Apart from the time interval of the reference, several other facts were annotated in the manual annotations, as was mentioned in Section \ref{sec:general-overview}. First of all, the target button of each RE was annotated. The count of distinct target buttons is 29.  

REs were also separated into 5 high-level categories depending on what is the target of the reference. The  overview of the categories is in the following list:

\begin{itemize}
\item
Target - Referring to the target button
\item
Group - Referring to a group of buttons, one of which is the target button
\item
Landmark object - Referring to a landmark (any object or room feature, but not a button) which will then be used to locate the target button
\item
Landmark button - Referring to a distractor button as a landmark
\item
Remove button -  Referring to a distractor button to exclude it
\end{itemize}

The percentage count of the categories is given in Table \ref{tab:res-groups}. References to target buttons are a dominant category. Around 10\% of the references are group references. References to landmarks occupy only 6\% of all references.

\begin{table}[!htbp]
 \centering
\begin{tabular}{lr}
\toprule
Category  & Percentage (\%)  \\
\midrule
Target   		& 82.47\\
Group 			& 10.34\\
Landmark object 	& 5.04\\
Landmark button	& 1.39\\
Remove button 	& 0.76\\
\bottomrule
\end{tabular}
\caption{Percentage of REs in the categories}
\label{tab:res-groups}
\end{table} 

Another layer of manual annotations looked into the content of the REs. It was done through annotating several semantic elements of the REs of the Target category. They are listed in the following list and their usage is summarised in Table \ref{tab:res-contents}. Please note that these elements are not necessarily exclusive with each other.

\begin{itemize}
\item
Type - RE expressed the target object as its type (``button'')
\item
One - RE expressed the target object as ``one''
\item
Pronoun - RE expressed the target object as a pronoun
\item
Color -  RE contained color of the target object
\item
Button location - RE contained relative location of the target object to a distracting button
\item
Object location - RE contained relative location of the target object to a distracting object (not a button)
\item 
IF location - RE contained relative location of the target object to the IF
\item
Room location - RE contained relative location of the target object to a room
\item
History - RE informed that the target object was already manipulated with
\end{itemize}

\begin{table}[!htbp]
 \centering
\begin{tabular}{lr}
\toprule
Element  & Percentage (\%)  \\
\midrule
Type   			& 55.35\\
Color			& 47.09\\
One 				& 26.29\\
Button location & 18.80\\
Object location 	& 16.67\\
IF location		& 11.62\\
Pronoun			& 10.70\\
History			& 6.88\\
Room location 	& 5.81\\
\bottomrule
\end{tabular}
\caption{Percentage of REs which contained a semantic element}
\label{tab:res-contents}
\end{table} 

From previous tables, we can see prevalence of relatively simple RE. However, the next section will show that the situation is more complex than it may seem from this section.

\section{Chains of references}
\label{sec:dataset-chains}
An interesting phenomenon I have noticed and further explored in the dataset are consecutive references to one button. It can be seen in the following sentences: ``Straight ahead of you there on the opposite wall there are two blue buttons. Press the one on the right. The one close to the picture.'' The IG started of with a references to a group of two buttons; the target button being one of those two. In the second sentence he picked out the target button from the group. In the last sentence the IG made another reference containing a landmark, adding redundant information. Since the references are concerned with one target button and follow each other relatively fast, I have called them chains of references (chains, in short). These chains are examples of non-standard referencing strategies, I was mentioning since the beginning of this paper.

The chains vary in length, from short ones, consisting of only two references, up to lengthy ones with eight references following each other. The example from previous paragraph is three references long. Figure \ref{fig:chains_len_histo} shows a histogram of the chains' length.

\begin{figure}[!htbp]
  \centering
	\includegraphics[width=0.8\textwidth]{Images/chains_len_histo}
	\caption{Histogram of the chain length}
	\label{fig:chains_len_histo}
\end{figure}

The chains are significant part of the discourse, in fact over 77\% of all RE belong to a chain. However, the chains have multiple linguistic functions, which makes them difficult to explore. Even inside one chain, there are often combination of functions. I have manually annotated some common functions of the chains. The most common one is to inform the IF that he is supposed to press the target button. A simple example of this function, which I call action function, is in following discourse: ``The red button in front of you. Press that one.'' It may sound redundant to use action function as the experiment progresses, since the IF are not manipulating the buttons in any other way than pressing them. But I have found out that it's often the case, that IG still use action functions in later stages of navigation.

Another common function is confirmation: ``That same red button we pressed before, we'll press that again. Yeah that one.'' The IG confirms at the end of the previous utterance that IF is looking at or heading to a correct target button.

The IG often utters a RE, which does not perfectly ``pick out'' the target button from the set of buttons in the room. The IG can make up for that information deficit with a confirmation or by further specifying with another RE. That is a specification function, as in following two sentences: ``Now that green button. You want the one closer to the lamp.''

When a group of buttons is utilized in a RE and the target button is part of that group, it is inevitable that the IG will have to make another RE to ``pick out'' the target button from the group. Therefore group references imply chains of references and should be considered as one of the functions. A simple example of the group function: ``Two blue buttons on the wall. Hit the blue button on the right side.''

When the IF has clearly chosen the wrong button, the IG will try to correct that error. I call that an error function. The following extract features this function: ``That blue button. No no no. The other. That one.''

A summary of the functions, which I have manually annotated, is in Table \ref{tab:chains-functions}. Please note that these functions are not exclusive. One chain can have both a confirmation and a specification function.

\begin{table}[!htbp]
 \centering
\begin{tabular}{lr}
\toprule
Function   & Chains containing it (\%)  \\
\midrule
Action    		& 66.16\\
Confirmation	 	& 29.29\\
Specification 	& 25.25\\
Group 	  		& 24.74\\
Error 			& 11.11\\
\bottomrule
\end{tabular}
\caption{Percentage of chains having specific functions}
\label{tab:chains-functions}
\end{table}

These chains will be further explored in the following chapter, but as one can already notice, they are complex language phenomenon.



